next steps:

- clean data
	if headline or body is empty, remove line
		empty, or not a string, or < 10 chars


- hand score 500 documents
- compare model accuracy with headlines vs doc bodies




#167 dupe headlines




print page
lead paragraph
headline
word_count	





noticed correlation of NAN print pages and weirdly formatted headlines (death/paid notices)

used dropna successfully


headlines, chars > 13





Saturday's goals
	#how do i really define joy?
		# it's my individual definition
		# neutral and negative are 0, upbeat is 1


	complete hand scoring, train algorithm
	- train with body (with stop words)
		- add stemmer



	- train with body, then headlines, then both

	score negatives?
	try boosting words

	k means
	explore other data sets

Sunday
	gut check, practice presentation




i re-calibrated

started scoring neutral things as positive - i.e. travel journalism


to create an uplifting experience, do I:
1) cherry-pick joyful articles
2) filter out the negative ones?

# Extra Security in Times Square for New Year's Eve - negative
# Times Square new years celebrations - positive

#clear negative: 
Brazil: Deadly Mudslide at Resort Near Rio

# clear positives
Freed Captive Is Reunited With His Family in Britain


# lots of grey areas
C.I.A. Takes On Expanded Role On Front Lines
Rush Limbaugh Released From Hospital
South Korea's Exports Surged Last Month - good for some, not others




word cloud?





  vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,
                                 stop_words='english')
    X_train = vectorizer.fit_transform(data_train.data)


RESULTS (mean accuracy):

100% of data (748):
GAUSS:
(lead_paragraph only)
0.908       0.89558233  0.89156627]

(headline only)
[ 0.732       0.78714859  0.74297189]

[headline + paragraph]
 0.908       0.89156627  0.8875502 ]

75% of data (561)
0.88235294  0.88770053  0.88235294]

50% of data (374):
GAUSS:
[0.848       0.824       0.85483871]

25% of data(187):
0.77777778  0.79032258  0.80645161]


MULTINOMIAL
100% of data:
 [0.9         0.90361446  0.90361446]

RANDOM FOREST:
N=10
0.87937743  0.8828125   0.87890625]

ANALYSIS:
lead_paragraph is what matters
multinomial slightly better than gauss

alpha 0, or 1 did not make a difference

#problems:
"needle in a haystack"
added 20 more positivies
now ratio is 94 / 675

NEXT:


add class priors? no.

add stemmer?
crack open model to see most powerful stop_word, go word
	need to crack open vectorizer 